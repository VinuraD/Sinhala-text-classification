{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b7b142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################################\n",
      "Training started..............................................................................\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d72de550354a27bc87514d272854ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "batch completed for epoch 0_0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d645fc2b9fc411ebb25ebd4a23cbf56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "batch completed for epoch 0_500000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf62425168040989e2f83db617060fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "batch completed for epoch 0_1000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1475df1422442e4b3b4406557779ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "batch completed for epoch 0_1500000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e127708e0a64b5fb133b9592ca6d233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "batch completed for epoch 0_2000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52952979116a459f9f4adc91bdcb5a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "batch completed for epoch 0_2500000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c4aca8b19a4f429dd93304f77e84ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "batch completed for epoch 0_3000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02328920aba04f3f9180a2aca6cef414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "batch completed for epoch 0_3500000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072e7692c1be4651bd3691ae812da439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "batch completed for epoch 0_4000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30359490b57e42718511b11423209c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "batch completed for epoch 0_4500000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5084f665823648fdbc11296a33f2d9b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "batch completed for epoch 0_5000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63283aa0962484493dc483bf16262a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "batch completed for epoch 0_5500000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8c47462bea42c0b5c8adee353d075f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "batch completed for epoch 0_6000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f166ebe4ce1847dd82756e44dcdf43fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "batch completed for epoch 0_6500000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5dc5eb40a44eb1be64f05d1f40b226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "batch completed for epoch 0_7000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e03aa93ed14a19b6ee6dda91643d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "batch completed for epoch 0_7500000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33a470e7dcc4c51a869a6e9efbe9c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import RobertaConfig\n",
    "from transformers import RobertaForMaskedLM\n",
    "from transformers import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        # store encodings internally\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        # return the number of samples\n",
    "        return self.encodings['input_ids'].shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # return dictionary of input_ids, attention_mask, and labels for index i\n",
    "        return {key: tensor[i] for key, tensor in self.encodings.items()}\n",
    "    \n",
    "def mlm(input_ids):\n",
    "    # input_ids = labels.detach().clone()\n",
    "    # create random array of floats with equal dims to input_ids\n",
    "    rand = torch.rand(input_ids.shape)\n",
    "    # mask random 15% where token is not 0 [PAD], 1 [CLS], or 2 [SEP]\n",
    "    mask_arr = (rand < .15) * (input_ids != 0) * (input_ids != 1) * (input_ids != 2)\n",
    "    # loop through each row in input_ids tensor (cannot do in parallel)\n",
    "    for i in range(input_ids.shape[0]):\n",
    "        # get indices of mask positions from mask array\n",
    "        # print(\"mask array shape:\", mask_arr.shape)\n",
    "        selection = torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "        # print(\"selection array shape:\", selection)\n",
    "        # mask input_ids\n",
    "        input_ids[i, selection] = 4 \n",
    "    return input_ids\n",
    "\n",
    "paths = [str(x) for x in Path('/userdirs/piyumal/roberta_sinhala/content/sinhala-dataset-creation/datasets/tokenized/').glob('**/*.txt')]\n",
    "tokenizer = RobertaTokenizer.from_pretrained('Roberta_tokenizer', max_len=512)\n",
    "\n",
    "with open('Sinhala_all_data.txt', 'r', encoding='utf-8') as fp:\n",
    "    lines = fp.read().split('\\n')\n",
    "    \n",
    "config = RobertaConfig(\n",
    "    vocab_size=52_000,  # we align this to the tokenizer vocab_size\n",
    "    max_position_embeddings=514,\n",
    "    hidden_size=768,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=12,\n",
    "    type_vocab_size=1\n",
    ")\n",
    "\n",
    "model = RobertaForMaskedLM(config)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# and move our model over to the selected device\n",
    "model.to(device)\n",
    "\n",
    "# activate training mode\n",
    "model.train()\n",
    "# initialize optimizer\n",
    "optim = AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "print(\"##############################################################################################\")\n",
    "print(\"Training started..............................................................................\")\n",
    "epochs = 2\n",
    "loss_values = []\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(lines), 5_00_000):\n",
    "        if i == (len(lines)//5_00_000)*5_00_000:\n",
    "            batch_data = tokenizer(lines[i:], max_length=512, padding='max_length', truncation=True)\n",
    "        else:\n",
    "            batch_data = tokenizer(lines[i:i+5_00_000], max_length=512, padding='max_length', truncation=True)\n",
    "        labels_all = torch.tensor(batch_data.input_ids)\n",
    "        mask_all = torch.tensor(batch_data.attention_mask)\n",
    "        input_ids_all = mlm(labels_all.detach().clone())\n",
    "        encodings = {'input_ids': input_ids_all, 'attention_mask': mask_all, 'labels': labels_all}\n",
    "        dataset = Dataset(encodings)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "    # setup loop with TQDM and dataloader\n",
    "        loop = tqdm(loader, leave=True)\n",
    "        for batch in loop:\n",
    "            # initialize calculated gradients (from prev step)\n",
    "            optim.zero_grad()\n",
    "            # pull all tensor batches required for training\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            # process\n",
    "            outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                            labels=labels)\n",
    "            # extract loss\n",
    "            loss = outputs.loss\n",
    "            # calculate loss for every parameter that needs grad update\n",
    "            loss.backward()\n",
    "            # update parameters\n",
    "            optim.step()\n",
    "            # print relevant info to progress bar\n",
    "            loop.set_description(f'Epoch: {epoch} Text Loading Iter: {i//5_00_000}')\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "            loss_values.append(loss.item())\n",
    "            del input_ids\n",
    "            del attention_mask\n",
    "            del labels\n",
    "        else:\n",
    "            model.save_pretrained(f'./Roberta_models/roberta_model_{epoch}_{i}')\n",
    "            del batch_data\n",
    "            del labels_all \n",
    "            del mask_all \n",
    "            del input_ids_all\n",
    "            gc.collect()\n",
    "            with open('loss_value_file', 'wb') as fp:\n",
    "                pickle.dump(loss_values, fp)\n",
    "            print(\"############################################################################################\")\n",
    "            print(f'batch completed for epoch {epoch}_{i}')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b2aa40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e481d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
